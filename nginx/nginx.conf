events {
    worker_connections 1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    types {
        application/javascript  js;
        text/css                css;
        text/html               html htm;
    }

    # ======================
    # Upload Size
    # ======================
    client_max_body_size 500M;

    # ======================
    # Performance
    # ======================
    sendfile        on;
    tcp_nopush      on;
    tcp_nodelay     on;
    keepalive_timeout 65;
    gzip on;
    gzip_types text/plain text/css application/json application/javascript text/xml;

    # ======================
    # Nginx Proxy Cache
    # Replaces the Redis caching layer entirely.
    # - keys_zone=api_cache:10m  → 10 MB for cache keys (~80k entries)
    # - max_size=100m             → 100 MB max disk usage
    # - inactive=120s             → evict entries not accessed in 2 min
    # ======================
    proxy_cache_path /var/cache/nginx/api_cache
                     levels=1:2
                     keys_zone=api_cache:10m
                     max_size=100m
                     inactive=120s
                     use_temp_path=off;

    # ======================
    # Map: flag non-GET methods so they bypass the cache
    # ======================
    map $request_method $no_cache_request {
        default  0;   # GET / HEAD → cacheable
        POST     1;
        PUT      1;
        DELETE   1;
        PATCH    1;
    }

    upstream api_service {
        server api:8080;
    }

    upstream client_proxy_service {
        server client_proxy:8001;
    }

    server {
        listen 80;

        root /usr/share/nginx/html;
        index index.html;

        # ======================
        # Static Files (JS/CSS only)
        # ======================
        location ~* \.(js|css|ico|svg|woff|woff2|ttf|eot)$ {
            include /etc/nginx/mime.types;
            add_header Cache-Control "no-cache";
            try_files $uri =404;
        }

        # ======================
        # Extracted Images
        # ======================
        location /api/extracted_images/ {
            alias /usr/share/nginx/images/extracted_images/;
            add_header Cache-Control "public, max-age=3600";
            try_files $uri =404;
        }

        # ======================
        # Chat Images
        # ======================
        location /api/chat_images/ {
            alias /usr/share/nginx/images/chat_images/;
            add_header Cache-Control "public, max-age=3600";
            try_files $uri =404;
        }

        # ======================
        # Batch Progress SSE — NEVER cached
        # Must be matched before the generic /client-api/ block.
        # ======================
        location ~* /client-api/batches/.*/progress {
            proxy_pass http://client_proxy_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;

            proxy_http_version 1.1;
            proxy_set_header Connection '';
            proxy_buffering off;
            proxy_cache off;
            proxy_read_timeout 600s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 600s;

            proxy_set_header X-Accel-Buffering no;
            add_header X-Accel-Buffering no;
            add_header Cache-Control no-cache;
            add_header Content-Type text/event-stream;
        }

        # ======================
        # Chat Stream SSE — NEVER cached
        # Exact match so it takes priority over the generic /client-api/ block.
        # ======================
        location = /client-api/chat/stream {
            proxy_pass http://client_proxy_service/client-api/chat/stream;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;

            proxy_http_version 1.1;
            proxy_set_header Connection '';
            proxy_buffering off;
            proxy_cache off;
            proxy_read_timeout 600s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 600s;

            proxy_set_header X-Accel-Buffering no;
            add_header X-Accel-Buffering no;
            add_header Cache-Control no-cache;
        }

        # ======================
        # Document Download / View — NEVER cached (binary streams)
        # ======================
        location ~* /client-api/documents/[^/]+/(download|view)$ {
            proxy_pass http://client_proxy_service;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_cache off;
            proxy_read_timeout 300s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
        }

        # ======================
        # Client Proxy — with Nginx-native caching
        #
        # What gets cached:
        #   ✅  GET /client-api/categories
        #   ✅  GET /client-api/categories/{id}/documents
        #   ✅  GET /client-api/documents
        #   ✅  GET /client-api/documents/{id}
        #   ✅  GET /client-api/chat          (list)
        #   ✅  GET /client-api/chat/{id}
        #   ✅  GET /client-api/batches/{id}  (snapshot)
        #
        # What is NOT cached (bypassed via $no_cache_request map):
        #   ❌  POST / PUT / DELETE / PATCH — mutations always hit upstream
        #
        # Staleness after mutations: ≤ 60s (same as the previous Redis TTL)
        # ======================
        location /client-api/ {
            proxy_pass http://client_proxy_service/client-api/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_read_timeout 300s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;

            # ── Cache settings ────────────────────────────────────────
            proxy_cache            api_cache;
            # Unique key: method + host + full URI (includes query string)
            proxy_cache_key        "$request_method:$host$request_uri";
            # Cache successful responses for 60 seconds
            proxy_cache_valid      200 60s;
            # Only cache GET requests
            proxy_cache_methods    GET;
            # Serve stale content while re-fetching on error or update
            proxy_cache_use_stale  error timeout updating http_500 http_502 http_503;
            # Collapse concurrent cache-miss requests into one upstream call
            proxy_cache_lock       on;

            # Bypass + skip storing for non-GET verbs (POST/PUT/DELETE/PATCH)
            proxy_cache_bypass     $no_cache_request;
            proxy_no_cache         $no_cache_request;

            # Expose cache status to the client for debugging (HIT / MISS / BYPASS / EXPIRED)
            add_header X-Cache-Status $upstream_cache_status always;
        }

        # ======================
        # Main API — no caching (main API manages its own data)
        # ======================
        location /api/ {
            proxy_pass http://api_service/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_read_timeout 300s;
            proxy_connect_timeout 300s;
            proxy_send_timeout 300s;
        }

        # ======================
        # Frontend SPA
        # ======================
        location / {
            try_files $uri $uri/ /index.html;
        }
    }
}